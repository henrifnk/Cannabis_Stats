---
title: "Power Analyse: Schwereinschätzung von Cannabis Delikten"
format: pdf
---

```{r setup, include=FALSE}
rm(list = ls())
library(ordinal)
library(parallel)
library(data.table)
library(ggplot2)
library(pwrss)
source("helpers.R")
eval = FALSE
set.seed(123L)
```

# Methoden

## Power Analyse mit herkömmlichen Methoden

Da die herkömmlichen Methoden mithilfe von Tests üblicher Weise nur für einfachere Modelle existieren, wurde für diese Analyse ein logisitsches Regresionsmodell angenommen. Dabei wird eine binäre Zielvariable angenommen (0/1: keine Strafe/schwere Strafe) und die Wahrscheinlichkeit, Teil von Gruppe 1 zu sein ($P_1$), modeliert. Bei der Base Probability ($P_0$) handelt es sich um die Wahrscheinlichkeit, Teil von Gruppe 1 zu sein, ohne den Einfluss der Kovariablen des Modells. Die Modellgleichung in einem solchen Fall lautet:

$$
ln(\frac{P_1}{1 - P_1})= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n
$$

mit:

$$
\beta_0 = ln(\frac{P_0}{1 - P_0})
$$

Das pwrss Package benutzt den Wald-Test(/z-Test) um die Signifikanz von Variablen zu schätzen und darauf basierend die nötige Stichprobegröße zu finden. Für diese Analyse wurde ein Signifikanzniveau von $\alpha = 0.05$ verwendet, sowie eine Power von 0.8. Die Funktion nutzt neben $P_0$ , $P_1$ (welches sich in diesem Fall um die vorhergesagte Wahrscheinlichkeit, wenn man $X_1$ (bzw. die Kovariable von Interesse) von 0 auf 1 erhöht, handelt), $\alpha$ und der Power noch ein Argument für die multiple Korrelation zwischen den Kovariablen in Form von dem korrigierten $R^2$. Für die Zwecke dieser Analyse wurde dieses Argument auf 0.5 gesetzt.

In dieser Analyse wurden verschiedene Kombinationen von $P_0$ und $P_1$ verwendet, um die benötigte Stichprobengröße für verschiedene Datenlagen abzuschätzen. Dabei wurde als minimale Veränderung zwischen den beiden eine Veränderung von 0.03 betrachtet.

Im Folgenden ist eine Tabelle mit verschiedenen Kombinationen von $P_0$ und $P_1$ , sowie der benötigten Stichprobengröße, um für diese Datenlage einen signifikanten Effekt festellen zu können, zu sehen:

```{r pwrss logistic regeression, include = FALSE}


p0 <- seq(0.1, 0.9, 0.1)

df_results <- data.frame(p0 = numeric(0), p1 = numeric(0),
                         sample_size = numeric(0))

for (i in seq(length(p0))) {
  for (j in c(-1, 1)) {
    sample_size <- pwrss.z.logreg(p0 = p0[i], p1 = p0[i] + j * 0.03, alpha = 0.05, power = 0.8,
                                  r2.other.x = 0.5)$n
    
    result_row <- data.frame(p0 = p0[i],
                             p1 = p0[i] + j * 0.03,
                             sample_size = as.integer(sample_size))
    
    df_results <- rbind(df_results, result_row)
  }
}
df_1 <- df_results[1:9,]
df_2 <- df_results[10:18,]
```

```{r sample sizes according to pwrss, echo=FALSE}
kableExtra::kable(t(df_1))
kableExtra::kable(t(df_2))
```

Für eine minimale Veränderung von 0.03 zwischen $P_0$ und $P_1$ bewegen sich die benötigten Stichpobengrößen zwischen ca. 1100 und 4400.

## Power Analyse mit simulierten Daten

Da das angestrebte Modell etwas komplexer ist, als das oben skizzierte Modell, wurde zusätzlich noch eine Power Analyse mithilfe von simultierten Daten durchgeführt. Dabei wurde ein kumulatives Logit-Modell für ordinale Zielvariablen geschätzt. Hierfür wurden die Daten für verschiedene Effektgrößen (zwischen -0.5 und 2.5) und Stichprobengrößen (zwischen 10 Personen und 3000 Personen) simuliert und anschließend ein Modell mit den Daten geschätzt. Zusätzlich zu den Effekten der Kovariablen wurden bei der Simulation der Daten noch Personen-Effekte $\mu_j,\ j \in 1, \ldots, 10$ im Intervall $[-3, 3]$ einbezogen, sowie verschiedene Intercepts.

Das geschätzte Modell benutzt jeweils eine ordinale Variable Y mit 8 Kategorien als Zielvariable. Der lineare Prädiktor des Modells lautet $Y∼age+treatment×setup$

Die folgende Tabelle zeigt den jeweiligen Effekt, die Effektgröße, die Power und die benöigte Stichprobengröße.

```{r settings, include=FALSE}
possible_pers <- c(10, seq(from=50, to=1e3, by=50), 1250, 1500, 2e3, 2.5e3, 3e3)
rep_measures <- 10
alpha <- 0.01     
sims <- 200 

beta = c("age" = 0.05, "educationHS" = -0.1, "educationSC" = -0.05,
         "educationOC" = 0.03, "gender" = -0.5, "treatmentMany" = 1.5,
         "setupAlcohol" = -0.5, "setupStealth" = 0.2, "setupCocain" = 2.5,
         "setupRobbery" = 3, "treatment:setupAlcohol" = -0.4,
         "treatment:setupStealth" = 0.4, "treatment:setupCocain" = 1.5,
         "treatment:setupRobbery" = 1)
intercepts <- c(-1, -3.5, -6, -7, -7.5, -7.75, -8)
p_eff = seq(-3, 3, length.out = 100)

power_exp = lapply(possible_pers, function(pers) {
  readRDS(paste0("powerexp_", pers, ".rds"))
})

effects = c("treatment", "setupAlcohol", "setupStealth", "setupCocain", "setupRobbery",
    "treatment:setupAlcohol", "treatment:setupStealth",
    "treatment:setupCocain", "treatment:setupRobbery")
power_analysis = lapply(effects, function(covar) {
    pwr = unlist(lapply(power_exp, function(exp) {
      p_values = sapply(exp, function(x) x[covar, "Pr(>|z|)"], simplify = "vector")
      power = mean(sapply(p_values, function(x) x < alpha))
    }))
    cbind.data.frame(power = pwr, persons = possible_pers, effect = covar)
  })
power_analysis = rbindlist(power_analysis)
effects[1] = "treatmentMany"

# in the data table get the row with the power closest to 0.85
pwer_sample = power_analysis[, .SD[which.min(abs(power - 0.85))], by = effect]
pwer_sample = cbind(pwer_sample, log_odds = beta[effects])
pwer_sample = pwer_sample[order(persons, -log_odds)]
pwer_sample = pwer_sample[, odds := exp(log_odds)]
```

```{r show_power_table, echo = FALSE}
kableExtra::kable(pwer_sample, digits = 2)
```

Die Ergebnisse zeigen, dass für alle simulierten Effekte bei einem verwendeten Signifikanzniveau von $\alpha = 0.05$ ab einer Stichprobengröße von 3000 eine Power größer als 0.8 erreicht werden kann.

# Empfehlung

Nach den Ergebnissen der Power Analyse, empfehlen wir eine Stichprobengröße von 3000-4000 Personen.
